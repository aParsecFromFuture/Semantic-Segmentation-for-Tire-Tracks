{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yolov5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Modules"
      ],
      "metadata": {
        "id": "CDmvqOt6Ye3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade torch torchvision torchaudio\n",
        "!pip install -q wandb # for visualization\n",
        "!pip install -q onnx # for saving weights\n",
        "\n",
        "# for more details https://wandb.ai/site"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt7uBXffWhxh",
        "outputId": "aaeddcba-25d1-4cd5-a376-c3295ac2cbd8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 18.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 62.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 68.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 70.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 78.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 81.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 78.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 78.6 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 13.1 MB 30.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import yaml\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "weah9DmZEuIo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hagrid2yolo(bbox):\n",
        "  return [bbox[0] + 0.5 * bbox[2], bbox[1] + 0.5 * bbox[3], bbox[2], bbox[3]]"
      ],
      "metadata": {
        "id": "mwbxrl_hcTlC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Downloading\n",
        "### src: https://github.com/hukenovs/hagrid"
      ],
      "metadata": {
        "id": "xG-ySTfyGiAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = requests.get('https://sc.link/AO5l')\n",
        "\n",
        "if res.status_code == 200:\n",
        "  with open('images.zip', 'wb') as f:\n",
        "    f.write(res.content)\n",
        "    print(\"Images successfully downloaded!\")\n",
        "else:\n",
        "  print(\"Images couldn't downloaded!\")\n",
        "\n",
        "res = requests.get('https://sc.link/EQ5g')\n",
        "\n",
        "if res.status_code == 200:\n",
        "  with open('annotations.zip', 'wb') as f:\n",
        "    f.write(res.content)\n",
        "    print(\"Annotations successfully downloaded!\")\n",
        "else:\n",
        "  print(\"Annotations couldn't downloaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BMmgHWkEt_a",
        "outputId": "8ba43f15-105b-4d57-b94a-3c05ec86b9bc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images successfully downloaded!\n",
            "Annotations successfully downloaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir images\n",
        "!unzip -qq images.zip -d images\n",
        "!rm images.zip\n",
        "\n",
        "!mkdir annotations\n",
        "!unzip -qq annotations.zip -d annotations\n",
        "!rm annotations.zip"
      ],
      "metadata": {
        "id": "3-7Tp-YoHCnk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting the Bounding Boxes"
      ],
      "metadata": {
        "id": "h5zvkp6xQ2EJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# old dirs\n",
        "\n",
        "old_img_dir = 'images'\n",
        "old_ann_dir = 'annotations/ann_subsample'\n",
        "\n",
        "## yolo-format dirs\n",
        "\n",
        "root = 'dataset'\n",
        "images = 'dataset/images'\n",
        "labels = 'dataset/labels'\n",
        "\n",
        "for path in [root, images, labels]:\n",
        "  if not os.path.exists(path):\n",
        "    os.mkdir(path)\n",
        "\n",
        "for path in glob.glob(os.path.join(old_ann_dir, '*.json')):\n",
        "  with open(path) as f:\n",
        "    js = json.load(f)\n",
        "\n",
        "    for key, val in js.items():\n",
        "      with open(os.path.join(labels, f'{key}.txt'), 'w') as f:\n",
        "        for bbox in val['bboxes']:\n",
        "          f.write('0 {0} {1} {2} {3}\\n'.format(*hagrid2yolo(bbox)))\n",
        "      \n",
        "      shutil.move(os.path.join(old_img_dir, path.split('/')[-1].replace('.json', ''), f'{key}.jpg'), images)"
      ],
      "metadata": {
        "id": "0GYl3TQjUvZ6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-Valid-Test Split"
      ],
      "metadata": {
        "id": "wmfQ2xUPQxCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir, valid_dir, test_dir = 'dataset/train', 'dataset/valid', 'dataset/test'\n",
        "\n",
        "for path in [train_dir, valid_dir, test_dir]:\n",
        "  if not os.path.exists(path):\n",
        "    os.mkdir(path)\n",
        "\n",
        "imgs = glob.glob(os.path.join(images, '*.jpg'))\n",
        "\n",
        "train_imgs, test_imgs = train_test_split(imgs, test_size=0.2, random_state=42)\n",
        "train_imgs, valid_imgs = train_test_split(train_imgs, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "GSnwVrjdPctb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for imgs, path in zip([train_imgs, valid_imgs, test_imgs], [train_dir, valid_dir, test_dir]):\n",
        "  for img in imgs:\n",
        "    label = img.replace(images, labels).replace('jpg', 'txt')\n",
        "    shutil.move(img, path)\n",
        "    shutil.move(label, path)"
      ],
      "metadata": {
        "id": "J97Ei6AVPuRZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r images annotations\n",
        "!rmdir dataset/images dataset/labels"
      ],
      "metadata": {
        "id": "FMHGbYnRRegM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Yolov5 Installing\n",
        "### src: https://github.com/ultralytics/yolov5"
      ],
      "metadata": {
        "id": "sEYoJYb7GtcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -q -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzjmGFGlEyQr",
        "outputId": "cece3cd0-5daa-4f55-d987-b16540ddcc42"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 11957, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 11957 (delta 0), reused 0 (delta 0), pack-reused 11953\u001b[K\n",
            "Receiving objects: 100% (11957/11957), 12.47 MiB | 27.33 MiB/s, done.\n",
            "Resolving deltas: 100% (8219/8219), done.\n",
            "/content/yolov5\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 5.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [{\n",
        "    'path': '../dataset',\n",
        "    'train': 'train',\n",
        "    'val': 'valid',\n",
        "    'test': 'test',\n",
        "    'nc': 1,\n",
        "    'names': ['hand']\n",
        "}]\n",
        "\n",
        "with open('dataset.yaml', 'w') as f:\n",
        "  yaml.dump_all(data, f)"
      ],
      "metadata": {
        "id": "zzqRI0KATCUZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "rJ921wIMIrRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640            \\\n",
        "                 --batch 32           \\\n",
        "                 --epochs 20          \\\n",
        "                 --data dataset.yaml  \\\n",
        "                 --weights yolov5m.pt"
      ],
      "metadata": {
        "id": "KkN-XyIBs_X4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc66419b-8c7f-448f-e01d-21e0645252a3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfarukcan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=, data=dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=20, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v6.2-46-g06831aa Python-3.7.13 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/yolov5/wandb/run-20220822_185716-2jb7cngj\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33methereal-waterfall-5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/farukcan/YOLOv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/farukcan/YOLOv5/runs/2jb7cngj\u001b[0m\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 17.5MB/s]\n",
            "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5m.pt to yolov5m.pt...\n",
            "100% 40.8M/40.8M [00:00<00:00, 207MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
            "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
            "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
            " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
            "Model summary: 369 layers, 20871318 parameters, 20871318 gradients, 48.2 GFLOPs\n",
            "\n",
            "Transferred 475/481 items from yolov5m.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/dataset/train' images and labels...1152 found, 0 missing, 0 empty, 0 corrupt: 100% 1152/1152 [00:00<00:00, 1792.64it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/dataset/valid' images and labels...288 found, 0 missing, 0 empty, 0 corrupt: 100% 288/288 [00:00<00:00, 762.26it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset/valid.cache\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.99 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/19      12.1G     0.0874    0.03263          0         62        640: 100% 36/36 [03:48<00:00,  6.35s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:11<00:00,  2.26s/it]\n",
            "                   all        288        444      0.225      0.357      0.177     0.0538\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/19      11.6G    0.05938     0.0238          0         80        640: 100% 36/36 [03:29<00:00,  5.83s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:11<00:00,  2.21s/it]\n",
            "                   all        288        444      0.504      0.546      0.533      0.207\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/19      12.7G    0.05453    0.01935          0         75        640: 100% 36/36 [03:26<00:00,  5.74s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:06<00:00,  1.29s/it]\n",
            "                   all        288        444      0.536      0.739      0.591      0.307\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/19      12.7G    0.04754    0.01587          0         93        640: 100% 36/36 [03:27<00:00,  5.77s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:10<00:00,  2.18s/it]\n",
            "                   all        288        444      0.738      0.737      0.828      0.456\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/19      12.7G     0.0399    0.01353          0         61        640: 100% 36/36 [03:26<00:00,  5.74s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:05<00:00,  1.18s/it]\n",
            "                   all        288        444      0.824      0.892      0.901      0.565\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/19      12.7G    0.03474    0.01217          0         86        640: 100% 36/36 [03:31<00:00,  5.86s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:09<00:00,  2.00s/it]\n",
            "                   all        288        444      0.943      0.925       0.97      0.653\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/19      12.7G    0.03222    0.01169          0         87        640: 100% 36/36 [03:26<00:00,  5.73s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:05<00:00,  1.18s/it]\n",
            "                   all        288        444      0.952      0.938      0.982      0.677\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/19      12.7G    0.02949    0.01086          0         79        640: 100% 36/36 [03:35<00:00,  5.98s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:10<00:00,  2.07s/it]\n",
            "                   all        288        444       0.95      0.944       0.98      0.683\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/19      12.7G    0.02758    0.01078          0         71        640: 100% 36/36 [03:32<00:00,  5.91s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:05<00:00,  1.14s/it]\n",
            "                   all        288        444      0.957      0.954      0.982      0.706\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/19      12.7G    0.02605     0.0105          0         81        640: 100% 36/36 [03:30<00:00,  5.84s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:10<00:00,  2.04s/it]\n",
            "                   all        288        444      0.951      0.957      0.983      0.722\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/19      12.7G    0.02419   0.009885          0         73        640: 100% 36/36 [03:24<00:00,  5.68s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:06<00:00,  1.38s/it]\n",
            "                   all        288        444      0.947      0.963      0.985      0.725\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/19      12.7G    0.02279   0.009688          0         86        640: 100% 36/36 [03:28<00:00,  5.80s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:10<00:00,  2.16s/it]\n",
            "                   all        288        444      0.967      0.953      0.984      0.735\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/19      12.7G    0.02189   0.009368          0        100        640: 100% 36/36 [03:27<00:00,  5.78s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:05<00:00,  1.12s/it]\n",
            "                   all        288        444      0.948       0.95      0.979      0.726\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/19      12.7G    0.02073   0.008824          0         79        640: 100% 36/36 [03:32<00:00,  5.91s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:09<00:00,  1.99s/it]\n",
            "                   all        288        444      0.971      0.959      0.983      0.767\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/19      12.7G    0.01972   0.009028          0         90        640: 100% 36/36 [03:26<00:00,  5.73s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:05<00:00,  1.18s/it]\n",
            "                   all        288        444      0.967      0.955      0.982      0.768\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/19      12.7G     0.0188   0.008514          0         75        640: 100% 36/36 [03:34<00:00,  5.97s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:10<00:00,  2.03s/it]\n",
            "                   all        288        444      0.968      0.963      0.983      0.755\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/19      12.7G    0.01796   0.008555          0         95        640: 100% 36/36 [03:32<00:00,  5.89s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:05<00:00,  1.18s/it]\n",
            "                   all        288        444      0.954      0.971      0.989      0.784\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/19      12.7G    0.01692   0.008396          0         81        640: 100% 36/36 [03:42<00:00,  6.17s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:10<00:00,  2.08s/it]\n",
            "                   all        288        444      0.969      0.959      0.987      0.788\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/19      12.7G    0.01639   0.008099          0         79        640: 100% 36/36 [03:27<00:00,  5.77s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:05<00:00,  1.15s/it]\n",
            "                   all        288        444      0.979       0.95      0.988      0.797\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/19      12.7G    0.01552   0.007769          0         66        640: 100% 36/36 [03:32<00:00,  5.91s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:10<00:00,  2.04s/it]\n",
            "                   all        288        444      0.961      0.957      0.986      0.794\n",
            "\n",
            "20 epochs completed in 1.249 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 42.2MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 42.2MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 290 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:25<00:00,  5.16s/it]\n",
            "                   all        288        444      0.979       0.95      0.988      0.797\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▄▅▇▇████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▂▃▅▆▇▇▇▇▇▇▇▇████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▄▄▆▇████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▃▅▅▇▇███████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▆▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss █▇▆▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss █▅▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▆███▇▇▆▆▅▅▅▄▄▃▃▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▆███▇▇▆▆▅▅▅▄▄▃▃▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 18\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.98803\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.79682\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.9791\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.9496\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.98805\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.79672\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.9791\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.9496\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01552\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.00777\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.01605\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.00689\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00109\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00109\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00109\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33methereal-waterfall-5\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/farukcan/YOLOv5/runs/2jb7cngj\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 337 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220822_185716-2jb7cngj/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "Fu5Idzu3OyqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --data dataset.yaml                     \\\n",
        "               --weight runs/train/exp/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbdwTBcnOyIp",
        "outputId": "1b35d09a-fc69-4d7f-aa0a-cd6414b0480d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=dataset.yaml, weights=['runs/train/exp/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-308-g602d7ff Python-3.7.13 torch-1.12.0+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 290 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/dataset/valid.cache' images and labels... 288 found, 0 missing, 0 empty, 0 corrupt: 100% 288/288 [00:00<?, ?it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 9/9 [00:17<00:00,  1.99s/it]\n",
            "                 all        288        430      0.962      0.967      0.987      0.775\n",
            "Speed: 0.2ms pre-process, 12.1ms inference, 1.3ms NMS per image at shape (32, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/val/exp3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "0eIswGxoKtSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --source ../dataset/test/                \\\n",
        "                  --weight runs/train/exp/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1vk-0tDKtHj",
        "outputId": "4b2b4133-fb2b-41a3-9a3a-579d860c3b8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp/weights/best.pt'], source=../dataset/test/, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-308-g602d7ff Python-3.7.13 torch-1.12.0+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 290 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
            "image 1/360 /content/dataset/test/000dfde3-a3a2-41b3-a3eb-e52744bf3ac4.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 2/360 /content/dataset/test/000dfea0-f327-4193-b55c-c7111f118245.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 3/360 /content/dataset/test/0014f118-ac28-4438-a72e-01b185dafc72.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 4/360 /content/dataset/test/001e9522-981a-4d9c-96b8-2a9d6be74faa.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 5/360 /content/dataset/test/002c0132-25cc-4ff6-b832-03fa82818e8a.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 6/360 /content/dataset/test/0035fcf9-da92-4167-a914-8cf6ac753160.jpg: 640x288 1 hand, Done. (0.019s)\n",
            "image 7/360 /content/dataset/test/003b73ea-beba-4bdc-bf65-fbabc5bbe168.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 8/360 /content/dataset/test/003f2700-fdf5-47c0-8f14-25f022d22d1d.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 9/360 /content/dataset/test/004c317a-ec98-41da-982a-e1ba5de685e8.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 10/360 /content/dataset/test/004fac40-47b8-4b32-b8a4-cb29c8d0946f.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 11/360 /content/dataset/test/005731ed-cab2-44c5-8fbc-384005cee981.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 12/360 /content/dataset/test/00713c1a-007e-4651-bef5-09c4019f19c6.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 13/360 /content/dataset/test/00879247-2d8c-4af5-bad4-e92e6ab0bd3a.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 14/360 /content/dataset/test/00952e09-59f1-444c-a2cf-4d2a05931e01.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 15/360 /content/dataset/test/009c6c68-7115-46b6-a276-2fc385da4d38.jpg: 640x512 2 hands, Done. (0.022s)\n",
            "image 16/360 /content/dataset/test/00a4dd61-5c15-4cfd-a514-545fcb4371d4.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 17/360 /content/dataset/test/00a6c250-88c5-4c1b-9713-0164e4a040ac.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 18/360 /content/dataset/test/00a9bb8b-a484-486f-8c9f-a815d21cfb10.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 19/360 /content/dataset/test/00ac6dfd-4e4c-40ac-9a16-1f411b4bb7f6.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 20/360 /content/dataset/test/00b0135c-b2ed-439a-9bc1-8db448a0c451.jpg: 384x640 1 hand, Done. (0.022s)\n",
            "image 21/360 /content/dataset/test/00b9ddcf-9308-40a4-ac01-ee011a9ec91e.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 22/360 /content/dataset/test/00bf711f-e2cc-4cb5-b0ac-573198cd6455.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 23/360 /content/dataset/test/00c7d5f3-ff27-455c-8b6e-cdc54aaaf427.jpg: 640x320 2 hands, Done. (0.026s)\n",
            "image 24/360 /content/dataset/test/00c7d7ed-4ca9-4a36-86bf-2a5b2848f95d.jpg: 640x512 1 hand, Done. (0.022s)\n",
            "image 25/360 /content/dataset/test/00cda552-8720-4165-b2a7-1b5e539ba8b2.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 26/360 /content/dataset/test/00d0a827-e4e1-4f74-99d8-b1880d06e5ee.jpg: 640x480 1 hand, Done. (0.024s)\n",
            "image 27/360 /content/dataset/test/00d3fcac-b592-43bd-b4bc-9243025563fb.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 28/360 /content/dataset/test/00d5944d-922c-4f56-bf60-2d9c4ade51a7.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 29/360 /content/dataset/test/00daa782-68f8-40ed-89de-985bef8f730f.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 30/360 /content/dataset/test/00db5a90-2f25-4875-a36b-cb871050034c.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 31/360 /content/dataset/test/00dee6a0-a258-4b06-bc82-2c96a4070487.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 32/360 /content/dataset/test/00df8fd8-6550-4b5b-b66d-67d257b1eb85.jpg: 480x640 1 hand, Done. (0.023s)\n",
            "image 33/360 /content/dataset/test/00e1e26a-ddac-4a6e-849e-9484e34548b0.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 34/360 /content/dataset/test/00e4a9b0-56fd-43e7-b389-7e398229af9f.jpg: 384x640 1 hand, Done. (0.022s)\n",
            "image 35/360 /content/dataset/test/00e78371-4696-42e7-a6af-37bee20614cf.jpg: 640x384 1 hand, Done. (0.023s)\n",
            "image 36/360 /content/dataset/test/00ee912b-b59e-49cb-bf1a-05772b493ae9.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 37/360 /content/dataset/test/00f46aea-67e3-47ec-8bb1-7db73c6e7792.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 38/360 /content/dataset/test/00f99e94-2386-4f84-9b46-464d1a0531a2.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 39/360 /content/dataset/test/0105a25e-6221-41b5-9336-89737250c401.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 40/360 /content/dataset/test/0106a9ee-1253-420f-a2a9-5dd0ab3557f8.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 41/360 /content/dataset/test/0107f95c-635e-4038-ba08-e3ce5d4a44a8.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 42/360 /content/dataset/test/01083636-1053-4abf-8b3a-f6f38b5491ce.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 43/360 /content/dataset/test/010bac92-854e-4333-97f6-59b70528c45b.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 44/360 /content/dataset/test/0111e4e2-847b-46f4-99c5-0c8c43e3fa1b.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 45/360 /content/dataset/test/01197ad5-3116-4b67-9871-f533cdd21d5a.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 46/360 /content/dataset/test/011c9d8b-98c4-4d6a-a4d5-cde54ae1a639.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 47/360 /content/dataset/test/011e271d-2d04-47eb-a46c-2bf049445ef7.jpg: 640x384 2 hands, Done. (0.023s)\n",
            "image 48/360 /content/dataset/test/012d8a6b-8c04-4b15-8d73-04242de0ae92.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 49/360 /content/dataset/test/0131e46b-a984-45d6-9e06-e750c58ad7fa.jpg: 480x640 1 hand, Done. (0.023s)\n",
            "image 50/360 /content/dataset/test/0143a273-46c9-43a2-856e-79386a33e7ec.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 51/360 /content/dataset/test/014cb122-084a-4ed8-898a-9a85b2db1a18.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 52/360 /content/dataset/test/0154fd8c-2746-4869-adef-2ab0ee8a236f.jpg: 640x320 2 hands, Done. (0.020s)\n",
            "image 53/360 /content/dataset/test/017e6c4c-2945-485f-9c1b-1d39f00c524e.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 54/360 /content/dataset/test/01883f07-2dc8-4e88-b2da-01e7149b6029.jpg: 480x640 1 hand, Done. (0.023s)\n",
            "image 55/360 /content/dataset/test/018b3f14-2244-41d0-9fde-ae2ffebc659c.jpg: 480x640 1 hand, Done. (0.023s)\n",
            "image 56/360 /content/dataset/test/018f48a1-f288-42ba-9b21-cd200d3d1fe1.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 57/360 /content/dataset/test/01932a51-ac81-4fde-9e62-d70c79def69f.jpg: 640x384 2 hands, Done. (0.023s)\n",
            "image 58/360 /content/dataset/test/01937fc1-f704-4421-9d13-83f06633a4d5.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 59/360 /content/dataset/test/019465c4-57aa-433b-958b-9ed82ec73cd5.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 60/360 /content/dataset/test/01a09d01-a0ce-4957-9330-9a5f41b9422e.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 61/360 /content/dataset/test/01a3298e-ecbe-42da-b31a-9b0be6eca430.jpg: 640x480 3 hands, Done. (0.022s)\n",
            "image 62/360 /content/dataset/test/01a4471f-e84a-4985-89df-64b77b112359.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 63/360 /content/dataset/test/01c38cfd-17d2-4bf2-9af8-674e1593a83b.jpg: 640x288 2 hands, Done. (0.019s)\n",
            "image 64/360 /content/dataset/test/01c4f492-09ee-49e1-986b-e29086d7883c.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 65/360 /content/dataset/test/01c586e2-c05c-4a10-bca5-c340f69b2443.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 66/360 /content/dataset/test/01c64760-02f4-4aa8-aad6-f2a388675ded.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 67/360 /content/dataset/test/01cd681c-a51b-493e-990e-d99ad96f63d0.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 68/360 /content/dataset/test/01d4e5dd-ec87-49f2-9d82-b9c8b7fae70a.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 69/360 /content/dataset/test/01ef94c3-3ea7-4628-969a-7a224fa15b2d.jpg: 640x320 1 hand, Done. (0.020s)\n",
            "image 70/360 /content/dataset/test/01f05cf2-fbf8-451d-b7b4-def80b698952.jpg: 640x320 2 hands, Done. (0.020s)\n",
            "image 71/360 /content/dataset/test/01fb610a-1349-4030-b200-bd3d43f200d8.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 72/360 /content/dataset/test/01fb88bd-bb8c-46e7-89b9-031583bb22e8.jpg: 640x640 2 hands, Done. (0.029s)\n",
            "image 73/360 /content/dataset/test/02015171-9f41-4eee-8956-c3e198d23de8.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 74/360 /content/dataset/test/02021cd2-8a70-4e8a-86bd-2bc236bd8885.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 75/360 /content/dataset/test/02045b8a-fb75-4593-a692-b6dba12da0ee.jpg: 640x384 2 hands, Done. (0.023s)\n",
            "image 76/360 /content/dataset/test/02096c62-3893-4a29-95b5-959728afd77d.jpg: 640x288 2 hands, Done. (0.019s)\n",
            "image 77/360 /content/dataset/test/021a97f7-d2a3-4f99-8e05-6d4d4777146a.jpg: 640x512 2 hands, Done. (0.022s)\n",
            "image 78/360 /content/dataset/test/021e6202-4b64-4a88-9807-08f20f1f5cb8.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 79/360 /content/dataset/test/0229de01-e5d9-4fc4-a0e2-0dd0a4b7bff7.jpg: 640x384 2 hands, Done. (0.023s)\n",
            "image 80/360 /content/dataset/test/02355348-6ac9-467d-b52f-1a740b9f8f2e.jpg: 640x384 2 hands, Done. (0.023s)\n",
            "image 81/360 /content/dataset/test/0240a3d7-7e33-478d-aab3-1ae80c779080.jpg: 480x640 1 hand, Done. (0.023s)\n",
            "image 82/360 /content/dataset/test/024a6d53-eb47-4959-b4fd-7aef882fbb50.jpg: 480x640 1 hand, Done. (0.023s)\n",
            "image 83/360 /content/dataset/test/025532b4-1070-4659-83de-a060aaa09bf2.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 84/360 /content/dataset/test/025abc10-f3ae-4fe1-b385-4654d0ddc2f8.jpg: 512x640 1 hand, Done. (0.023s)\n",
            "image 85/360 /content/dataset/test/0260c4ca-e702-4994-b56e-1b50095d9e03.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 86/360 /content/dataset/test/0260ec35-710a-4225-ad6f-f776452e7b83.jpg: 640x320 1 hand, Done. (0.020s)\n",
            "image 87/360 /content/dataset/test/02638d7e-ab64-45be-ad87-53fb0ac34762.jpg: 384x640 1 hand, Done. (0.022s)\n",
            "image 88/360 /content/dataset/test/026c6346-9d79-4328-802c-3026f1a7df49.jpg: 640x384 1 hand, Done. (0.023s)\n",
            "image 89/360 /content/dataset/test/026e78fd-899b-4bf2-8d8c-aa020e5f40e9.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 90/360 /content/dataset/test/02786303-79a4-4cb7-aead-23fcf151cf40.jpg: 640x640 2 hands, Done. (0.029s)\n",
            "image 91/360 /content/dataset/test/0279a7d3-2be1-4e66-b8a2-18fc175fc5a1.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 92/360 /content/dataset/test/027b34aa-20a1-4267-8765-08a47a46eee7.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 93/360 /content/dataset/test/027cc6ae-7cd9-470c-9643-3b9381d990c8.jpg: 640x384 2 hands, Done. (0.023s)\n",
            "image 94/360 /content/dataset/test/0284539c-d36e-4b1f-9ff0-4a80cdcb5972.jpg: 384x640 1 hand, Done. (0.022s)\n",
            "image 95/360 /content/dataset/test/02890265-6869-4490-98f0-069bf01b06be.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 96/360 /content/dataset/test/028e5825-a2be-431c-83e6-9c06b72f9d6a.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 97/360 /content/dataset/test/029794b3-f099-44eb-bcaf-5c88eab802b6.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 98/360 /content/dataset/test/029829f5-e9ca-4011-b4d1-1736c27df1d8.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 99/360 /content/dataset/test/029d627a-5135-4e06-b8ac-0e203023faa3.jpg: 384x640 2 hands, Done. (0.022s)\n",
            "image 100/360 /content/dataset/test/02b382be-6523-4322-8e19-50fc196288e5.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 101/360 /content/dataset/test/02b942fe-b8c5-4162-976d-38870da86c39.jpg: 384x640 1 hand, Done. (0.022s)\n",
            "image 102/360 /content/dataset/test/02b9bdf4-007d-4e5e-ae7e-f1b35edf7602.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 103/360 /content/dataset/test/02bac857-eb30-4ca3-8e65-44fde95b34c0.jpg: 640x320 2 hands, Done. (0.020s)\n",
            "image 104/360 /content/dataset/test/02bc7606-3f59-4d00-84c9-9c2141c0541f.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 105/360 /content/dataset/test/02bf8c95-abfc-4358-a3b0-caa71a8b32cf.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 106/360 /content/dataset/test/02d0b3c8-8717-4c33-b189-43898d77b1da.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 107/360 /content/dataset/test/02d8e051-a8f7-4f2b-b2bf-ac56e01fc6db.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 108/360 /content/dataset/test/02dcafaa-4eec-4052-b014-a1d766fc47a5.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 109/360 /content/dataset/test/02e06f96-9e5a-4d47-bcd8-769df3d5dc34.jpg: 384x640 2 hands, Done. (0.022s)\n",
            "image 110/360 /content/dataset/test/02f102d2-72bd-4300-8fc2-0da222e6a09c.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 111/360 /content/dataset/test/02ffc536-5477-493c-a0f7-e84d2120f04e.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 112/360 /content/dataset/test/0308eb7b-4896-4a28-acaa-f18727166576.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 113/360 /content/dataset/test/030f27d3-e76c-47d1-ae38-d0ee26a757f5.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 114/360 /content/dataset/test/03118bdc-9b5d-4f0f-910a-43755d3e862a.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 115/360 /content/dataset/test/031684a6-29bb-426e-8914-302278666570.jpg: 640x512 1 hand, Done. (0.022s)\n",
            "image 116/360 /content/dataset/test/03203ffc-42c5-4bea-a586-40114aa45ba5.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 117/360 /content/dataset/test/0322d3d9-ae02-49c1-8380-e96332d25c97.jpg: 480x640 1 hand, Done. (0.023s)\n",
            "image 118/360 /content/dataset/test/0324564e-73dd-4b38-897d-cd8a5dd01966.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 119/360 /content/dataset/test/0329ab93-5b22-447c-bcd0-fbd50dabf6c0.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 120/360 /content/dataset/test/032d79e5-b94c-4e12-a0e9-1c80a2f3ae0b.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 121/360 /content/dataset/test/034cb33c-772b-4269-9468-eb6c11f59066.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 122/360 /content/dataset/test/035560fd-9e7d-478f-a398-56ff9c8d940d.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 123/360 /content/dataset/test/035683d3-55bc-4ac7-9fd6-6e236efde9d1.jpg: 640x384 2 hands, Done. (0.023s)\n",
            "image 124/360 /content/dataset/test/035e96f6-4e47-467f-9d33-5ed09203ddd4.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 125/360 /content/dataset/test/03643c20-5e0b-4a4c-aaab-843f3cbd846a.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 126/360 /content/dataset/test/03650a3b-6563-48f7-aa1f-d4fdf1c1dfd8.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 127/360 /content/dataset/test/03728440-a146-4c8e-864c-56861746cd1d.jpg: 640x384 2 hands, Done. (0.023s)\n",
            "image 128/360 /content/dataset/test/037fe95f-6dce-4253-85ae-0345c15d4545.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 129/360 /content/dataset/test/0381336c-27ee-4036-9b14-bd1519733863.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 130/360 /content/dataset/test/0381b0db-827e-41bd-90a7-3f39144778de.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 131/360 /content/dataset/test/038d76ed-9d15-42f3-8a1c-78f4870addc5.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 132/360 /content/dataset/test/0393a9ca-96ec-42d7-bf1a-0e34ff0696fc.jpg: 480x640 1 hand, Done. (0.023s)\n",
            "image 133/360 /content/dataset/test/03a52a97-70aa-484d-90e6-507eb2443a43.jpg: 640x384 1 hand, Done. (0.023s)\n",
            "image 134/360 /content/dataset/test/03ba4ad1-c554-4eaf-a273-be8c5acae854.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 135/360 /content/dataset/test/03c45817-1f5a-4639-94c2-21e898dd7028.jpg: 640x320 2 hands, Done. (0.020s)\n",
            "image 136/360 /content/dataset/test/03c70265-cdf2-4764-bdc8-b23a0015b31a.jpg: 320x640 2 hands, Done. (0.025s)\n",
            "image 137/360 /content/dataset/test/03cb8675-fbcc-4070-a47e-9158c7306778.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 138/360 /content/dataset/test/03cd470a-d82c-4a74-8faf-feabcd1c558b.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 139/360 /content/dataset/test/03dcd6c5-6f97-4cb8-8310-2bbaa3f7c6bb.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 140/360 /content/dataset/test/03ec2a83-bd86-45cc-b0b8-99b29ad29a5d.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 141/360 /content/dataset/test/03ecc37c-d5f0-485e-a929-98f38588a0fa.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 142/360 /content/dataset/test/03efed3d-4f8c-4762-b594-2a14b944444f.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 143/360 /content/dataset/test/03f1a3f6-d17b-4690-988d-1dec1dfa9b6d.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 144/360 /content/dataset/test/03f3129f-2fb0-46fe-8b3c-f0e42a14d6a2.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 145/360 /content/dataset/test/03faaaf7-e2a8-4c29-9f99-d69b40bd324e.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 146/360 /content/dataset/test/0401d6f5-ff79-4706-a7c3-3fba8c024cba.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 147/360 /content/dataset/test/04031bb5-cd39-4529-b285-8671ff44214b.jpg: 640x384 2 hands, Done. (0.023s)\n",
            "image 148/360 /content/dataset/test/04042884-b6f2-489d-86f0-95753a605f91.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 149/360 /content/dataset/test/040dec99-16b1-4b0d-9a54-9bf28e1849b4.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 150/360 /content/dataset/test/041ebd0e-1730-428f-99bd-5b39a1db52b6.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 151/360 /content/dataset/test/0427b250-a020-4578-aeb8-e2d546dd38ee.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 152/360 /content/dataset/test/043031bd-b8c7-4309-a165-4cdbcec8d5e8.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 153/360 /content/dataset/test/043f1e6d-f1f8-4180-a241-bceda4bca62a.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 154/360 /content/dataset/test/044308a2-ec87-4658-bca3-6fd8d16868bd.jpg: 480x640 1 hand, Done. (0.023s)\n",
            "image 155/360 /content/dataset/test/0449bb10-6f60-419a-8e18-5680d5cf6dab.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 156/360 /content/dataset/test/044af4c2-4374-444e-8984-2defe75ecfe0.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 157/360 /content/dataset/test/045062ee-0c2c-41d4-adc6-375af45d7e88.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 158/360 /content/dataset/test/0453b63a-8cf9-4b64-894b-e57dc07c5306.jpg: 640x384 1 hand, Done. (0.023s)\n",
            "image 159/360 /content/dataset/test/0459508e-6be3-4494-939c-cf74fa0c9c29.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 160/360 /content/dataset/test/045b6ef5-972f-424e-bc24-a700bdf23254.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 161/360 /content/dataset/test/0464c869-19bf-4df6-a852-11ba85bc1fe7.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 162/360 /content/dataset/test/04745c30-505a-4a1e-be71-f97b6ea335f5.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 163/360 /content/dataset/test/04792259-3032-4ebb-a2ab-ef47a5da766e.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 164/360 /content/dataset/test/047a7a3e-2881-466f-bf0f-8e8635f24cf0.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 165/360 /content/dataset/test/0480aa8b-deb9-4c35-9920-25e7480672c5.jpg: 640x640 2 hands, Done. (0.029s)\n",
            "image 166/360 /content/dataset/test/0487d1d7-2dac-48b6-979e-656c9dcf13f5.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 167/360 /content/dataset/test/049130ea-36c7-460e-84cd-811fa0da431e.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 168/360 /content/dataset/test/0493f82c-1578-4acc-ba3e-4884b7c9783c.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 169/360 /content/dataset/test/04a09fbe-ac7d-4453-9ee0-e29fcaed15bc.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 170/360 /content/dataset/test/04a7cacc-36e1-4064-a11b-6e95a4a10b57.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 171/360 /content/dataset/test/04ba263b-3d25-4dc9-9918-7a6075280718.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 172/360 /content/dataset/test/04d0c305-4775-4905-9bab-92ffb17bfcc6.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 173/360 /content/dataset/test/04ea9e7b-7596-422b-b965-83db0b2c8059.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 174/360 /content/dataset/test/04ed14a5-5518-4df2-bf19-524d265ad747.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 175/360 /content/dataset/test/05167068-095e-4d2b-ab48-533c74e15b0e.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 176/360 /content/dataset/test/0516ab39-9dd3-41bf-9707-ccea0dbf985f.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 177/360 /content/dataset/test/051a711c-2d60-4e08-b86e-a3c6a7fdc73e.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 178/360 /content/dataset/test/0534147c-4548-4ab4-9a8c-f297b43e8ffb.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 179/360 /content/dataset/test/0541ebd7-79f1-4fa6-af58-5e6e78dc9e33.jpg: 640x384 2 hands, Done. (0.023s)\n",
            "image 180/360 /content/dataset/test/05543fda-c2e2-437f-b7e9-9304ce68d7ac.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 181/360 /content/dataset/test/0557de6d-1ec9-446b-82e9-944536ba4fc2.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 182/360 /content/dataset/test/055cbe75-f563-49e2-9c4f-86a1fb47b40f.jpg: 640x288 2 hands, Done. (0.019s)\n",
            "image 183/360 /content/dataset/test/05652b5e-a119-484d-8c94-d9fdfaccd9ba.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 184/360 /content/dataset/test/0567d5bd-69d6-4efb-99bf-e1df9887669d.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 185/360 /content/dataset/test/05793ec6-d810-4795-ae03-a85bde5b29a3.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 186/360 /content/dataset/test/0588d4a9-93c5-4d94-a051-00a16b424f8b.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 187/360 /content/dataset/test/059b45f4-3f1a-4de2-ad54-fa454817361a.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 188/360 /content/dataset/test/05a52f6e-4e8e-4d02-891f-8ff3913d1117.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 189/360 /content/dataset/test/05a6f421-55b4-4830-b393-a15e6e6c2dc4.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 190/360 /content/dataset/test/05ac5cef-2d67-491c-8ea2-18c20f6aaa57.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 191/360 /content/dataset/test/05b2193c-b6dd-43de-a5a4-90941f67e066.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 192/360 /content/dataset/test/05b40519-a5e1-47fb-b68b-2c45c19b7805.jpg: 640x512 2 hands, Done. (0.022s)\n",
            "image 193/360 /content/dataset/test/05b56ad9-6742-4465-a6ce-ce7fa786014a.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 194/360 /content/dataset/test/05b97c20-fbb8-4172-8488-fdddfa356a96.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 195/360 /content/dataset/test/05b9f9ab-6a12-4450-8cb5-7be7b2f22fd1.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 196/360 /content/dataset/test/05c70758-d8e1-48cd-82c6-28fec6226b66.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 197/360 /content/dataset/test/05c87ec4-e35b-494f-a13e-cdd4b4e001af.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 198/360 /content/dataset/test/05d73a69-72c7-4fc7-892d-84034980dd8d.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 199/360 /content/dataset/test/05ddc9f6-4db0-48e1-b9a5-128db049c756.jpg: 320x640 2 hands, Done. (0.020s)\n",
            "image 200/360 /content/dataset/test/05e9ae91-f11e-4de3-b450-8ddd2cc586ab.jpg: 480x640 1 hand, Done. (0.023s)\n",
            "image 201/360 /content/dataset/test/05f0116f-094f-4062-aca0-6789ad40b846.jpg: 480x640 1 hand, Done. (0.023s)\n",
            "image 202/360 /content/dataset/test/05fec3e8-39f7-493d-bc70-58df604fd95c.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 203/360 /content/dataset/test/0607c790-9bb6-4e9a-8622-9027c82c4863.jpg: 640x512 1 hand, Done. (0.022s)\n",
            "image 204/360 /content/dataset/test/06093401-fce2-4434-9603-1261612f01d2.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 205/360 /content/dataset/test/060e140b-97a3-4700-94d1-e95c1ef598fb.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 206/360 /content/dataset/test/060fc025-15e8-4cce-bfd5-c01c909e5525.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 207/360 /content/dataset/test/061a231c-ea7d-43c0-b712-d4a86c30698e.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 208/360 /content/dataset/test/061f11a6-a8cd-482b-9c2b-13e09d87eeeb.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 209/360 /content/dataset/test/062ba42e-035a-4088-adbd-bee3a08da9cb.jpg: 640x320 2 hands, Done. (0.020s)\n",
            "image 210/360 /content/dataset/test/063bb81b-8890-4687-84e8-b4968b7e69cb.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 211/360 /content/dataset/test/0652a490-4d26-47b8-a43e-7d36ec2740cf.jpg: 640x512 1 hand, Done. (0.022s)\n",
            "image 212/360 /content/dataset/test/0661e3c3-5b54-43f6-818b-3440476a8ebe.jpg: 640x320 2 hands, Done. (0.020s)\n",
            "image 213/360 /content/dataset/test/0669b6a5-9bac-487e-9c62-4c7d91920a6b.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 214/360 /content/dataset/test/06739a65-7079-4e88-91fa-0c5837145510.jpg: 384x640 1 hand, Done. (0.022s)\n",
            "image 215/360 /content/dataset/test/06752c14-c847-4968-899f-4b219029776a.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 216/360 /content/dataset/test/067b0078-1256-4c06-a18c-160e7eec7a9b.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 217/360 /content/dataset/test/069075e8-a7d2-496b-a9aa-9ee497ff8598.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 218/360 /content/dataset/test/06983888-62ed-4e25-b701-354e983c3372.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 219/360 /content/dataset/test/06a11bff-1ab9-4941-bf58-a6c1d9232f7f.jpg: 480x640 3 hands, Done. (0.023s)\n",
            "image 220/360 /content/dataset/test/06ac5665-d1f4-4586-9dd8-c8fbe93bd142.jpg: 640x320 2 hands, Done. (0.020s)\n",
            "image 221/360 /content/dataset/test/06b0fd08-aedc-4625-9787-d9f5129be574.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 222/360 /content/dataset/test/06bf18e1-3288-4647-9d3e-97f79d061392.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 223/360 /content/dataset/test/06c3748b-f659-479e-b3e7-0bdf768c023e.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 224/360 /content/dataset/test/06c958d4-88bd-4946-9632-151c7f7a91c4.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 225/360 /content/dataset/test/06d66a9d-bfbd-4a8a-a0ff-6c0f7e641118.jpg: 480x640 1 hand, Done. (0.023s)\n",
            "image 226/360 /content/dataset/test/06eb85ff-e3a7-4d9e-a232-75f635985837.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 227/360 /content/dataset/test/07146bd6-aa8d-44bf-be8c-163c7a9c467a.jpg: 512x640 2 hands, Done. (0.023s)\n",
            "image 228/360 /content/dataset/test/0725f2af-7623-4e2c-9178-ca4e511072dc.jpg: 640x288 2 hands, Done. (0.019s)\n",
            "image 229/360 /content/dataset/test/07290fbc-6565-47ed-8879-8e2fdc5e8f28.jpg: 640x512 2 hands, Done. (0.022s)\n",
            "image 230/360 /content/dataset/test/07382505-9a44-43a5-a87e-8ee44e76bfaf.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 231/360 /content/dataset/test/073ed106-bc1b-446d-9223-379b4233b544.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 232/360 /content/dataset/test/0744fba0-78e6-4789-9372-34e5d8ed2b7e.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 233/360 /content/dataset/test/076a6681-5f30-46be-9499-11bcdcfce463.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 234/360 /content/dataset/test/078f509f-e8ba-43ff-b0e5-5c40192c945e.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 235/360 /content/dataset/test/07aa877d-fcf4-488d-a498-1860cb74bcc9.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 236/360 /content/dataset/test/07e78c54-9498-47b7-95d9-3b32f1c2f4bf.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 237/360 /content/dataset/test/082b2083-c056-4735-a9f6-3df3593283d9.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 238/360 /content/dataset/test/084ec62d-b27e-4bb7-b836-975edb892a32.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 239/360 /content/dataset/test/085abd8c-bb77-49f0-a2f0-30164ae67441.jpg: 384x640 1 hand, Done. (0.022s)\n",
            "image 240/360 /content/dataset/test/08d5402c-0727-4795-961e-20e2c8cc1148.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 241/360 /content/dataset/test/08df4a1d-0e1f-4fd8-8c35-86d173dcddf5.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 242/360 /content/dataset/test/098243de-24a6-47a3-b4cc-333d0389b8ad.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 243/360 /content/dataset/test/099b5a1e-990b-4e4d-b5ef-c87a6b90890f.jpg: 640x384 1 hand, Done. (0.023s)\n",
            "image 244/360 /content/dataset/test/0a77d5fe-3396-43a2-9feb-3e5822bba4e6.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 245/360 /content/dataset/test/0aa328d1-fce5-4346-8b14-1d3080e8e9be.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 246/360 /content/dataset/test/0bba11b4-f9a2-4cf9-88a1-72bc1c4cc7df.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 247/360 /content/dataset/test/0c0e888b-6289-486f-a4af-c4be342ac29f.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 248/360 /content/dataset/test/0d303909-120a-41e9-9005-e445e955982d.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 249/360 /content/dataset/test/0d4599a7-295e-46f8-b8be-6c803e3014a9.jpg: 384x640 2 hands, Done. (0.022s)\n",
            "image 250/360 /content/dataset/test/0dc10b9d-ec26-4acb-a360-7eb9b52654ba.jpg: 320x640 2 hands, Done. (0.020s)\n",
            "image 251/360 /content/dataset/test/0e5f176f-ff0e-45c0-bbba-06ac2846de76.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 252/360 /content/dataset/test/0ea9d994-c7c4-4dfe-b1e5-68c5420c94f1.jpg: 384x640 1 hand, Done. (0.022s)\n",
            "image 253/360 /content/dataset/test/0f5fec47-1d6b-41f3-af85-141ad6aa99e5.jpg: 640x480 3 hands, Done. (0.022s)\n",
            "image 254/360 /content/dataset/test/0fe2a4dd-58e4-4935-9234-2268c5dc0f85.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 255/360 /content/dataset/test/10cec4f0-e142-4d7b-b301-08b72ceeaf02.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 256/360 /content/dataset/test/10f36ba4-8cd8-4515-b5b6-063c77110e1b.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 257/360 /content/dataset/test/1258c30e-f3f5-4897-affd-6b004b8ac4c6.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 258/360 /content/dataset/test/13c9ac86-4335-4b9a-825c-f18ec8f86bc1.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 259/360 /content/dataset/test/147a1893-1689-4b65-86a0-adcee9d53889.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 260/360 /content/dataset/test/1896b056-cc20-4d45-a190-4e87417b3f68.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 261/360 /content/dataset/test/19ae0c3c-a5d7-4986-b1bb-5ac263a2e7cd.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 262/360 /content/dataset/test/1babac0a-62d3-44bc-862d-604e357a52ad.jpg: 640x480 3 hands, Done. (0.022s)\n",
            "image 263/360 /content/dataset/test/1bd1d664-dec4-4fd8-9111-988815968932.jpg: 640x320 2 hands, Done. (0.020s)\n",
            "image 264/360 /content/dataset/test/1c997c2d-d3af-4845-9f74-f6a1ddcb7bf1.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 265/360 /content/dataset/test/1df0d03e-2d86-4e50-864e-70fe415d74ba.jpg: 640x288 2 hands, Done. (0.019s)\n",
            "image 266/360 /content/dataset/test/1e7409fd-eb1e-4dde-a7c5-02e2ddfa91bb.jpg: 480x640 1 hand, Done. (0.023s)\n",
            "image 267/360 /content/dataset/test/1f64cfdb-e173-4d54-bbac-2c7e29f3772a.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 268/360 /content/dataset/test/200c3af1-0d72-465d-bb6d-b4e46d153a95.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 269/360 /content/dataset/test/205f9782-6840-44d1-be1c-6cff087447af.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 270/360 /content/dataset/test/2117c75e-2ea1-4467-b863-47aa35c45e82.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 271/360 /content/dataset/test/2125d467-4c00-43eb-835f-c6e724663f9a.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 272/360 /content/dataset/test/2169bf59-923a-453d-809a-d3368e049838.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 273/360 /content/dataset/test/2170938b-ca55-4998-8c87-9c46808b7452.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 274/360 /content/dataset/test/22d137a0-ef60-4b35-88b8-6075193d89e0.jpg: 480x640 1 hand, Done. (0.023s)\n",
            "image 275/360 /content/dataset/test/22fb3aa1-f8d2-453f-92d9-59993c89fbfe.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 276/360 /content/dataset/test/24d89868-d99d-4840-bb95-75cded598896.jpg: 640x640 2 hands, Done. (0.029s)\n",
            "image 277/360 /content/dataset/test/268d912f-0616-4a55-81e1-9fa60460e00d.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 278/360 /content/dataset/test/2719d117-1915-4fc5-818d-5ca294ac56db.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 279/360 /content/dataset/test/2740fe4b-54df-4fac-89e0-58c9c7c5b9d9.jpg: 640x480 3 hands, Done. (0.022s)\n",
            "image 280/360 /content/dataset/test/286438f4-e439-42a4-b8ec-8792e52d85a6.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 281/360 /content/dataset/test/290d4c31-a8ec-4d91-95c8-f9ee5ef8551a.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 282/360 /content/dataset/test/2a50661c-881d-4d16-a17b-ecf66e055445.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 283/360 /content/dataset/test/2baab879-938d-4288-83b7-55b6bacced82.jpg: 384x640 2 hands, Done. (0.022s)\n",
            "image 284/360 /content/dataset/test/2c45b3d1-916b-4bda-8af5-f24ebb729e61.jpg: 640x480 3 hands, Done. (0.022s)\n",
            "image 285/360 /content/dataset/test/2d68c840-d06e-4f2a-b641-ec23bddc53aa.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 286/360 /content/dataset/test/2eb70e2d-edd7-4467-b46b-1c089515d4c6.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 287/360 /content/dataset/test/2fd15650-ecad-4bb4-b290-d744be5ec7eb.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 288/360 /content/dataset/test/304deb71-6e3d-4be6-abc2-23272027cc66.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 289/360 /content/dataset/test/3063f4b1-d869-4ebe-82eb-989b09d37785.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 290/360 /content/dataset/test/32b32eeb-a04b-46b4-ad02-df19fd230bf1.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 291/360 /content/dataset/test/338162b6-eae8-4f57-8c65-22ce04d6b396.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 292/360 /content/dataset/test/358e7185-545b-470d-94bf-68f88df59805.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 293/360 /content/dataset/test/37d7ccf0-fc3d-40b0-b9c2-48995c8f89bd.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 294/360 /content/dataset/test/3a040604-a613-448e-a19a-2d8068a75754.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 295/360 /content/dataset/test/3a4676af-2872-4de0-bbb7-a05f53d53648.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 296/360 /content/dataset/test/3ccb47f3-b62a-42da-b904-be07744ca1d1.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 297/360 /content/dataset/test/3cf1ca1b-f8a0-4a7f-b00b-cbc6095c5bb2.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 298/360 /content/dataset/test/3dcb7be3-3c84-4fc9-888f-b0d41a87ce64.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 299/360 /content/dataset/test/3f1e7090-d14d-46dc-8d34-afdb623c2b49.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 300/360 /content/dataset/test/40c1b7d8-ed27-4997-a239-293e59979dc7.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 301/360 /content/dataset/test/420c8de8-3a27-4569-b6d6-09693334cca6.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 302/360 /content/dataset/test/45025ebd-2c3a-41b1-8e45-ec45f9de2e5c.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 303/360 /content/dataset/test/46dd8883-e2f3-4095-9de2-36a5559aebbc.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 304/360 /content/dataset/test/48a64d01-8b6f-4cef-8a06-1a98dd1bcbf8.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 305/360 /content/dataset/test/4befef33-8307-4b03-9744-bd836800e345.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 306/360 /content/dataset/test/4c7b11fa-5ebf-4158-9954-906922b6d792.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 307/360 /content/dataset/test/4e88ae3e-8e4b-441e-91d0-6e154dd8e256.jpg: 384x640 2 hands, Done. (0.022s)\n",
            "image 308/360 /content/dataset/test/54422d1f-a721-4376-8ea5-b417b174e82f.jpg: 640x320 2 hands, Done. (0.020s)\n",
            "image 309/360 /content/dataset/test/559b7c8d-b8d1-429e-92c6-9aa0784916bc.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 310/360 /content/dataset/test/579fde92-2d38-4496-892d-1e62bcfedeee.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 311/360 /content/dataset/test/5ade9bf2-07bd-4d9b-b3a3-fc736267cfeb.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 312/360 /content/dataset/test/5cb21a04-a696-4218-8360-42579db02a5a.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 313/360 /content/dataset/test/5e300741-c3f3-45ae-ae8c-a7bd06e33742.jpg: 480x640 1 hand, Done. (0.023s)\n",
            "image 314/360 /content/dataset/test/5ed00387-230a-40f6-85dc-c5d149cb23d2.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 315/360 /content/dataset/test/61bcc40e-3ede-4715-a4f2-f84ca6661c0d.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 316/360 /content/dataset/test/648e0c48-caac-47ab-9532-09aa930da31f.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 317/360 /content/dataset/test/69c8d6e4-e988-4758-9fe4-1cd3107b18c2.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 318/360 /content/dataset/test/6f484a33-46c6-4c8e-bad0-b178f266e2be.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 319/360 /content/dataset/test/718064f8-1f12-467a-9a6f-076e1d95c2e1.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 320/360 /content/dataset/test/71f034b8-0603-4947-bbaf-16370366a92f.jpg: 640x512 1 hand, Done. (0.022s)\n",
            "image 321/360 /content/dataset/test/7836a824-0a8c-43b8-a1f5-70690ef77203.jpg: 480x640 3 hands, Done. (0.023s)\n",
            "image 322/360 /content/dataset/test/78f723ab-21ba-4fed-bd60-91b7bcf17d86.jpg: 384x640 2 hands, Done. (0.022s)\n",
            "image 323/360 /content/dataset/test/790bf7f7-277b-494c-b253-ec084cd95a4e.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 324/360 /content/dataset/test/793ab286-adbc-4308-93b8-0f1bba0ccb81.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 325/360 /content/dataset/test/7daaa071-94c6-4b80-9d19-2b236059c04f.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 326/360 /content/dataset/test/7e478ba7-938d-4cc8-a3e0-6bd39ba0d714.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 327/360 /content/dataset/test/8056862b-3110-40a4-b22a-4616f92d1a52.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 328/360 /content/dataset/test/83295293-53de-4f4a-a9e1-627f949eeaa1.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 329/360 /content/dataset/test/84da3d22-28d4-4791-bd50-57a37d5d3771.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 330/360 /content/dataset/test/8ef676e1-279b-45ed-954a-da5141812fce.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 331/360 /content/dataset/test/90164d61-9900-43ad-8a36-7052327b4a9a.jpg: 640x480 3 hands, Done. (0.022s)\n",
            "image 332/360 /content/dataset/test/9064b0e5-fd0f-4454-9977-5427d0bbaf55.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 333/360 /content/dataset/test/909b50aa-0f7c-4c7d-95c0-277a6a1d2e10.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 334/360 /content/dataset/test/93a04e41-4a56-4676-aa34-2984be88ce86.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 335/360 /content/dataset/test/95935508-bff5-40a3-97f3-80b0da45b511.jpg: 384x640 2 hands, Done. (0.022s)\n",
            "image 336/360 /content/dataset/test/970d474a-a39e-4f51-a633-a9a6e2c38da3.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 337/360 /content/dataset/test/984f8bb7-c249-45af-9479-fb28b8d3d1ff.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 338/360 /content/dataset/test/9c8715ab-ee07-4c2e-8a54-eb893a156662.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 339/360 /content/dataset/test/9f6b5f0e-3653-4122-8cac-47cd7beae76f.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 340/360 /content/dataset/test/a8c73d74-4d2f-42f1-a2d0-f36e3167c250.jpg: 640x512 1 hand, Done. (0.022s)\n",
            "image 341/360 /content/dataset/test/aa4fad56-634f-4f3d-8494-90474c9e18b1.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 342/360 /content/dataset/test/b2acb9ec-7dcb-4bec-b16e-4c21014b1ea4.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "image 343/360 /content/dataset/test/b2e9fbe5-d298-4fd3-a187-8991fe4739e1.jpg: 384x640 1 hand, Done. (0.022s)\n",
            "image 344/360 /content/dataset/test/b83f04d2-6172-4c1a-bd21-cea6d8757b04.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 345/360 /content/dataset/test/bce28663-a9a6-4057-b561-f22de7e75059.jpg: 640x480 4 hands, Done. (0.022s)\n",
            "image 346/360 /content/dataset/test/c1e7b863-ab00-4cf3-bdae-cc4d848789b5.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 347/360 /content/dataset/test/c462885d-1afb-43c1-8e00-8619f26f4a99.jpg: 640x384 1 hand, Done. (0.023s)\n",
            "image 348/360 /content/dataset/test/c5389f63-b635-4aba-afab-2fd9125cef6a.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 349/360 /content/dataset/test/c5c99019-d61b-4ff6-b009-5fbaeae5d878.jpg: 480x640 2 hands, Done. (0.023s)\n",
            "image 350/360 /content/dataset/test/cba847bb-17b1-48b3-98cb-b8a58393670f.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 351/360 /content/dataset/test/cceed2d9-cf5c-4f43-8f15-5e0e2c4356fd.jpg: 480x640 1 hand, Done. (0.023s)\n",
            "image 352/360 /content/dataset/test/dba6d732-0383-4b3c-800b-bf8b8b9851cd.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 353/360 /content/dataset/test/dfbda925-2ae9-4df2-b88d-8fdb28b1caeb.jpg: 384x640 2 hands, Done. (0.022s)\n",
            "image 354/360 /content/dataset/test/e11f118c-ca91-42dc-863e-5224edb85ba1.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 355/360 /content/dataset/test/f24d8119-2a3e-4f47-b79e-009685b10c5d.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 356/360 /content/dataset/test/f407a51b-0e79-4bc6-a611-6e97df794784.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 357/360 /content/dataset/test/f66f4adb-9849-4160-97db-5cd19f1caffe.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 358/360 /content/dataset/test/fc07c33f-354b-497c-88cf-269be876e3b7.jpg: 640x480 2 hands, Done. (0.022s)\n",
            "image 359/360 /content/dataset/test/fcb64ecf-f6cf-4f04-a820-ad74fba52c9a.jpg: 640x384 2 hands, Done. (0.023s)\n",
            "image 360/360 /content/dataset/test/fecb2d23-7829-4865-a405-2ac5f5be3324.jpg: 640x480 1 hand, Done. (0.022s)\n",
            "Speed: 0.5ms pre-process, 22.2ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export"
      ],
      "metadata": {
        "id": "ifxFSsW7Hu0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python export.py --weights yolov7-tiny.pt \\\n",
        "                  --simplify               \\\n",
        "                  --topk-all 100           \\\n",
        "                  --iou-thres 0.65         \\\n",
        "                  --conf-thres 0.35        \\\n",
        "                  --imgsz 640              "
      ],
      "metadata": {
        "id": "hufaJUaXHvSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Yolov7 Installing\n",
        "### src: https://github.com/WongKinYiu/yolov7"
      ],
      "metadata": {
        "id": "ec7T6_HXTuyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7.git\n",
        "%cd yolov7\n",
        "!pip install -q -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Dbq8LxEQ5nu",
        "outputId": "9bebd0f2-20e6-47ff-b039-b5c750fd2567"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 749, done.\u001b[K\n",
            "remote: Total 749 (delta 0), reused 0 (delta 0), pack-reused 749\u001b[K\n",
            "Receiving objects: 100% (749/749), 67.46 MiB | 15.93 MiB/s, done.\n",
            "Resolving deltas: 100% (375/375), done.\n",
            "/content/yolov7\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 35.9 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [{\n",
        "    'train': '../dataset/train',\n",
        "    'val': '../dataset/valid',\n",
        "    'test': '../dataset/test',\n",
        "    'nc': 1,\n",
        "    'names': ['hand']\n",
        "}]\n",
        "\n",
        "with open('data/dataset.yaml', 'w') as f:\n",
        "  yaml.dump_all(data, f)"
      ],
      "metadata": {
        "id": "Jstmi30fRH-Z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "z28O-UHSDs3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data data/dataset.yaml           \\\n",
        "                 --weights yolov7.pt                \\\n",
        "                 --img 640                          \\\n",
        "                 --epochs 20                        \\\n",
        "                 --batch-size 32                    \\\n",
        "                 --device 0"
      ],
      "metadata": {
        "id": "VOy4K8shR1xs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bfb129f-93f4-42e4-ab1b-865327f51fe6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOR 🚀 v0.1-105-g064c71e torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=32, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7.yaml', data='data/dataset.yaml', device='0', entity=None, epochs=20, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/hyp.scratch.custom.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp2', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=32, upload_dataset=False, weights='yolov7.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfarukcan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/yolov7/wandb/run-20220822_203236-12e83h4a\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/farukcan/YOLOR\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/farukcan/YOLOR/runs/12e83h4a\u001b[0m\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     34156  models.yolo.IDetect                     [1, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 415 layers, 37196556 parameters, 37196556 gradients, 105.1 GFLOPS\n",
            "\n",
            "Transferred 552/566 items from yolov7.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../dataset/train.cache' images and labels... 1152 found, 0 missing, 0 empty, 0 corrupted: 100% 1152/1152 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../dataset/valid.cache' images and labels... 288 found, 0 missing, 0 empty, 0 corrupted: 100% 288/288 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 6.02, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp2\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "  0% 0/36 [00:29<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 613, in <module>\n",
            "    train(hyp, opt, device, tb_writer)\n",
            "  File \"train.py\", line 361, in train\n",
            "    pred = model(imgs)  # forward\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/yolov7/models/yolo.py\", line 599, in forward\n",
            "    return self.forward_once(x, profile)  # single-scale inference, train\n",
            "  File \"/content/yolov7/models/yolo.py\", line 625, in forward_once\n",
            "    x = m(x)  # run\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/yolov7/models/common.py\", line 108, in forward\n",
            "    return self.act(self.bn(self.conv(x)))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 457, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 454, in _conv_forward\n",
            "    self.padding, self.dilation, self.groups)\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 100.00 MiB (GPU 0; 14.76 GiB total capacity; 13.26 GiB already allocated; 81.75 MiB free; 13.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mexp2\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/farukcan/YOLOR/runs/12e83h4a\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220822_203236-12e83h4a/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "LvwPrs_QDvVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --data data/dataset.yaml                  \\\n",
        "                --img 640                                 \\\n",
        "                --batch 32                                \\\n",
        "                --conf 0.001                              \\\n",
        "                --iou 0.65                                \\\n",
        "                --device 0                                \\\n",
        "                --weights runs/train/exp3/weights/best.pt"
      ],
      "metadata": {
        "id": "5JFJWJjJpi-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e587b6f-4c05-47cf-b8b7-e830b6169876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=32, conf_thres=0.001, data='data/dataset.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', verbose=False, weights=['runs/train/exp3/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-105-g064c71e torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../dataset/valid.cache' images and labels... 288 found, 0 missing, 0 empty, 0 corrupted: 100% 288/288 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 9/9 [00:17<00:00,  1.92s/it]\n",
            "                 all         288         429       0.943       0.881       0.955       0.737\n",
            "Speed: 10.6/1.9/12.5 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "Results saved to runs/test/exp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "Uz2FHFbSDw3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights yolov7.pt     \\\n",
        "                  --conf 0.25             \\\n",
        "                  --img-size 640          \\\n",
        "                  --source inference/"
      ],
      "metadata": {
        "id": "bzDdYeuUCP1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export"
      ],
      "metadata": {
        "id": "R47WW986EASr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python export.py --weights yolov7-tiny.pt \\\n",
        "                  --grid                   \\\n",
        "                  --end2end                \\\n",
        "                  --simplify               \\\n",
        "                  --topk-all 100           \\\n",
        "                  --iou-thres 0.65         \\\n",
        "                  --conf-thres 0.35        \\\n",
        "                  --img-size 640           \\\n",
        "                  --max-wh 640         "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHq-yWc9EAif",
        "outputId": "eaa6d9ca-e19c-4603-a8f3-feb0578e424a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Import onnx_graphsurgeon failure: No module named 'onnx_graphsurgeon'\n",
            "Namespace(batch_size=1, conf_thres=0.35, device='cpu', dynamic=False, dynamic_batch=False, end2end=True, fp16=False, grid=True, img_size=[640, 640], include_nms=False, int8=False, iou_thres=0.65, max_wh=640, simplify=True, topk_all=100, weights='yolov7-tiny.pt')\n",
            "YOLOR 🚀 v0.1-105-g064c71e torch 1.12.1+cu113 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 200 layers, 6219709 parameters, 6219709 gradients\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\n",
            "Starting TorchScript export with torch 1.12.1+cu113...\n",
            "/content/yolov7/models/yolo.py:52: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
            "TorchScript export success, saved as yolov7-tiny.torchscript.pt\n",
            "CoreML export failure: No module named 'coremltools'\n",
            "\n",
            "Starting TorchScript-Lite export with torch 1.12.1+cu113...\n",
            "TorchScript-Lite export success, saved as yolov7-tiny.torchscript.ptl\n",
            "\n",
            "Starting ONNX export with onnx 1.12.0...\n",
            "onnxruntime\n",
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:477.)\n",
            "  return self._grad\n",
            "/content/yolov7/models/experimental.py:99: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  batches = torch.randint(0, batch, (num_det,)).sort()[0].to(device)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/onnx/symbolic_opset9.py:4194: UserWarning: Exporting aten::index operator of advanced indexing in opset 12 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
            "  + \"If indices include negative values, the exported graph will produce incorrect results.\"\n",
            "Simplifier failure: No module named 'onnxsim'\n",
            "ONNX export success, saved as yolov7-tiny.onnx\n",
            "\n",
            "Export complete (9.17s). Visualize with https://github.com/lutzroeder/netron.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bknlHeXrEdfJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}